{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiJ1z3pSAZ89"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# PART 1: INSTALL, IMPORTS & SETTINGS\n",
        "# ==========================================\n",
        "!pip install -U -q gradio nltk pandas matplotlib requests google-generativeai google-api-python-client google-auth-httplib2 google-auth-oauthlib fpdf transformers torch pillow\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "import google.generativeai as genai\n",
        "from fpdf import FPDF\n",
        "from transformers import pipeline\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "# --- Configuration ---\n",
        "# Set API Key\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "GEMINI_API_KEY = os.environ[\"GEMINI_API_KEY\"]\n",
        "\n",
        "# Constants\n",
        "FOLDER_ID = '1BWa5Hy-4aTifH0zHULoPMwi9qL-s_5-l'\n",
        "BASE_URL = \"https://server-cloud-v645.onrender.com/\"\n",
        "MODEL_ID = \"linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification\"\n",
        "\n",
        "# NLTK Downloads\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "# Global Variables placeholders (will be filled in Main)\n",
        "GLOBAL_CACHE = { \"temperature\": None, \"humidity\": None, \"soil\": None }\n",
        "DOC_TITLES = {}\n",
        "ARTICLES = {}\n",
        "drive_service = None\n",
        "plant_classifier = None\n",
        "engine = None\n",
        "ACTIVE_MODEL = \"models/gemini-pro\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XAusb1ay7QBx"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# PART 2: HELPER FUNCTIONS & CLASSES\n",
        "# ==========================================\n",
        "\n",
        "# --- 1. Drive & File Helpers ---\n",
        "def get_files_from_folder(folder_id):\n",
        "    try:\n",
        "        results = drive_service.files().list(\n",
        "            q=f\"'{folder_id}' in parents and mimeType='application/vnd.google-apps.document' and trashed=false\",\n",
        "            fields=\"files(id, name)\", pageSize=20\n",
        "        ).execute()\n",
        "        return results.get('files', [])\n",
        "    except: return []\n",
        "\n",
        "def fetch_gdoc_content(file_id):\n",
        "    try:\n",
        "        content = drive_service.files().export_media(fileId=file_id, mimeType='text/plain').execute()\n",
        "        return content.decode('utf-8')\n",
        "    except: return \"\"\n",
        "\n",
        "# --- 2. Search Engine Logic (Class) ---\n",
        "class LectureSearchEngine:\n",
        "    def __init__(self):\n",
        "        self.word_locations = defaultdict(list)\n",
        "        self.documents = {}\n",
        "        self.titles = {}\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.stop_words.update({'a', 'an', 'the', 'and', 'or', 'in', 'on', 'at', 'to', 'for', 'of', 'with'})\n",
        "\n",
        "    def build_index(self, docs, titles):\n",
        "        self.documents = docs\n",
        "        self.titles = titles\n",
        "        self.word_locations.clear()\n",
        "        for doc_id, content in self.documents.items():\n",
        "            words = re.findall(r'\\w+', content.lower())\n",
        "            word_counts = defaultdict(int)\n",
        "            for word in words:\n",
        "                if word not in self.stop_words:\n",
        "                    word_counts[word] += 1\n",
        "            for word, count in word_counts.items():\n",
        "                self.word_locations[word].append((doc_id, count))\n",
        "\n",
        "    def get_context(self, content, query_words, window=150):\n",
        "        content_lower = content.lower()\n",
        "        best_idx = -1\n",
        "        for word in query_words:\n",
        "            idx = content_lower.find(word)\n",
        "            if idx != -1:\n",
        "                best_idx = idx\n",
        "                break\n",
        "        if best_idx != -1:\n",
        "            start = max(0, best_idx - 50)\n",
        "            end = min(len(content), best_idx + window)\n",
        "            return \"...\" + content[start:end].replace(\"\\n\", \" \") + \"...\"\n",
        "        return content[:200] + \"...\"\n",
        "\n",
        "    def search(self, query, num_results=3):\n",
        "        query_words = [word.lower() for word in re.findall(r'\\w+', query) if word.lower() not in self.stop_words]\n",
        "        if not query_words: return []\n",
        "        page_scores = defaultdict(lambda: {'matches': 0, 'total_freq': 0})\n",
        "        for word in query_words:\n",
        "            for doc_id, freq in self.word_locations.get(word, []):\n",
        "                page_scores[doc_id]['matches'] += 1\n",
        "                page_scores[doc_id]['total_freq'] += freq\n",
        "        ranked_results = [(doc_id, scores['matches'], scores['total_freq']) for doc_id, scores in page_scores.items()]\n",
        "        ranked_results.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
        "        results = []\n",
        "        for doc_id, matches, total_freq in ranked_results[:num_results]:\n",
        "            title = self.titles.get(doc_id, \"Unknown\")\n",
        "            content = self.documents.get(doc_id, \"\")\n",
        "            context = self.get_context(content, query_words)\n",
        "            results.append({'title': title, 'score': f\"Matches: {matches}, Freq: {total_freq}\", 'context': context})\n",
        "        return results\n",
        "\n",
        "# --- 3. Gemini & RAG Helpers ---\n",
        "def get_working_model():\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    try:\n",
        "        models = [m for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "        for m in models:\n",
        "            if 'flash' in m.name.lower(): return m.name\n",
        "        if models: return models[0].name\n",
        "        return \"models/gemini-pro\"\n",
        "    except: return \"models/gemini-pro\"\n",
        "\n",
        "def search_engine_rag(query):\n",
        "    if not ARTICLES: return \"‚ö†Ô∏è Error: No documents loaded.\"\n",
        "    results = engine.search(query)\n",
        "    if not results: return f\"No results found for: '{query}'\"\n",
        "    output_log = f\"üîé Found {len(results)} docs (Ranked by Matches & Freq)\\n\" + \"=\"*40 + \"\\n\"\n",
        "    context_text = []\n",
        "    for res in results:\n",
        "        output_log += f\"\\nüìÑ [{res['title']}] ({res['score']})\\n - {res['context']}\\n\"\n",
        "        context_text.append(f\"Source ({res['title']}): {res['context']}\")\n",
        "    try:\n",
        "        model = genai.GenerativeModel(ACTIVE_MODEL)\n",
        "        prompt = (f\"Question: {query}\\nBase your answer ONLY on the following context:\\n\" + \"\\n\".join(context_text))\n",
        "        response = model.generate_content(prompt)\n",
        "        gemini_summary = f\"\\nü§ñ AI Answer:\\n{response.text}\\n\"\n",
        "    except Exception as e: gemini_summary = f\"\\n(AI Error: {e})\\n\"\n",
        "    return gemini_summary + \"\\n\" + output_log\n",
        "\n",
        "def get_index_table():\n",
        "    data = []\n",
        "    if engine:\n",
        "        for i, (word, locs) in enumerate(engine.word_locations.items()):\n",
        "            if i >= 100: break\n",
        "            data.append({\"term\": word, \"docs\": str(locs)})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# --- 4. IoT Helpers ---\n",
        "def fetch_data_as_df(feed, limit):\n",
        "    try:\n",
        "        resp = requests.get(f\"{BASE_URL}/history\", params={\"feed\": feed, \"limit\": limit}, timeout=5)\n",
        "        data = resp.json()\n",
        "        if \"data\" in data and len(data[\"data\"]) > 0:\n",
        "            df = pd.DataFrame(data[\"data\"])\n",
        "            df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
        "            df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
        "            df = df.sort_values(\"created_at\")\n",
        "            GLOBAL_CACHE[feed] = df\n",
        "            return df\n",
        "    except: return None\n",
        "    return None\n",
        "\n",
        "def create_plot(df, title, color):\n",
        "    if df is None or df.empty: return None\n",
        "    fig, ax = plt.subplots(figsize=(8, 3.5))\n",
        "    ax.plot(df[\"created_at\"], df[\"value\"], marker='.', linestyle='-', color=color, linewidth=1.5)\n",
        "    ax.set_title(title)\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def update_iot_view(chk_temp, chk_hum, chk_soil, chk_json, limit):\n",
        "    fig_temp, fig_hum, fig_soil, json_file = None, None, None, None\n",
        "    log_messages = []\n",
        "    export_data = {}\n",
        "    if chk_temp:\n",
        "        df = fetch_data_as_df(\"temperature\", limit)\n",
        "        if df is not None:\n",
        "            fig_temp = create_plot(df, \"Temp\", \"red\")\n",
        "            export_data[\"temperature\"] = df.to_dict(orient=\"records\")\n",
        "    if chk_hum:\n",
        "        df = fetch_data_as_df(\"humidity\", limit)\n",
        "        if df is not None:\n",
        "            fig_hum = create_plot(df, \"Hum\", \"blue\")\n",
        "            export_data[\"humidity\"] = df.to_dict(orient=\"records\")\n",
        "    if chk_soil:\n",
        "        df = fetch_data_as_df(\"soil\", limit)\n",
        "        if df is not None:\n",
        "            fig_soil = create_plot(df, \"Soil\", \"brown\")\n",
        "            export_data[\"soil\"] = df.to_dict(orient=\"records\")\n",
        "    if chk_json:\n",
        "        json_file = \"iot_data.json\"\n",
        "        with open(json_file, 'w') as f: json.dump(export_data, f, default=str)\n",
        "        log_messages.append(\"JSON Saved!\")\n",
        "    return fig_temp, fig_hum, fig_soil, json_file, \"\\n\".join(log_messages)\n",
        "\n",
        "def refresh_dashboard_real():\n",
        "    limit = 20\n",
        "    df_t = fetch_data_as_df(\"temperature\", limit)\n",
        "    df_h = fetch_data_as_df(\"humidity\", limit)\n",
        "    df_s = fetch_data_as_df(\"soil\", limit)\n",
        "    fig_t = create_plot(df_t, \"Temp Trend\", \"#ff6b6b\")\n",
        "    fig_h = create_plot(df_h, \"Hum Trend\", \"#4ecdc4\")\n",
        "    fig_s = create_plot(df_s, \"Soil Trend\", \"#8d6e63\")\n",
        "    val_t = df_t.iloc[-1][\"value\"] if df_t is not None else 0\n",
        "    val_h = df_h.iloc[-1][\"value\"] if df_h is not None else 0\n",
        "    val_s = df_s.iloc[-1][\"value\"] if df_s is not None else 0\n",
        "    status = \"Warning ‚ö†Ô∏è\" if val_t > 35 else \"OK ‚úÖ\"\n",
        "    return fig_t, fig_h, fig_s, f\"{val_t} ¬∞C\", f\"{val_h} %\", f\"{val_s}\", status\n",
        "\n",
        "# --- 5. Image AI Helpers ---\n",
        "def analyze_image(img):\n",
        "    if img is None: return \"‚ö†Ô∏è Please upload an image.\"\n",
        "    if plant_classifier is None: return \"‚ùå Model not loaded.\"\n",
        "    try:\n",
        "        raw_image = PILImage.fromarray(img.astype('uint8'), 'RGB')\n",
        "        results = plant_classifier(raw_image)\n",
        "        top_result = results[0]\n",
        "        label = top_result['label']\n",
        "        score = top_result['score']\n",
        "        if \"healthy\" in label.lower(): return f\"‚úÖ Healthy ({label})\\nConfidence: {score:.1%}\"\n",
        "        else: return f\"‚ö†Ô∏è Potential Issue: {label.replace('_', ' ').title()}\\nConfidence: {score:.1%}\"\n",
        "    except Exception as e: return f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "# --- 6. PDF Report Helpers ---\n",
        "class PDFReport(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 15)\n",
        "        self.cell(0, 10, 'IoT System Report', 0, 1, 'C')\n",
        "        self.ln(5)\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.set_fill_color(200, 220, 255)\n",
        "        self.cell(0, 10, title, 0, 1, 'L', 1)\n",
        "        self.ln(4)\n",
        "    def chapter_body(self, df):\n",
        "        self.set_font('Arial', '', 10)\n",
        "        self.cell(90, 8, 'Timestamp', 1)\n",
        "        self.cell(40, 8, 'Value', 1)\n",
        "        self.ln()\n",
        "        if df is not None and not df.empty:\n",
        "            for index, row in df.sort_values(\"created_at\", ascending=False).head(50).iterrows():\n",
        "                self.cell(90, 8, str(row['created_at']), 1)\n",
        "                self.cell(40, 8, str(row['value']), 1)\n",
        "                self.ln()\n",
        "        self.ln(10)\n",
        "\n",
        "def generate_pdf_report():\n",
        "    pdf = PDFReport()\n",
        "    pdf.add_page()\n",
        "    for feed in [\"temperature\", \"humidity\", \"soil\"]:\n",
        "        df = GLOBAL_CACHE.get(feed)\n",
        "        if df is None: df = fetch_data_as_df(feed, 100)\n",
        "        pdf.chapter_title(f\"{feed.capitalize()} Data\")\n",
        "        pdf.chapter_body(df)\n",
        "    filename = \"iot_report.pdf\"\n",
        "    pdf.output(filename)\n",
        "    return filename, f\"‚úÖ Report Saved to {filename}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dcStoFV27Srm",
        "outputId": "d49626d0-abcd-4dc2-b1a1-fa2a63a47996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Connecting to Google Drive... Please approve.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Drive Connected!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Found 5 documents.\n",
            "üìö Building Search Index...\n",
            "ü§ñ Active Text AI: models/gemini-2.5-flash\n",
            "üîÑ Loading Vision Model (linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/mobilenet_v2/feature_extraction_mobilenet_v2.py:30: FutureWarning: The class MobileNetV2FeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use MobileNetV2ImageProcessor instead.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "/tmp/ipython-input-3289238560.py:66: UserWarning: The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: theme, js. Please pass these parameters to launch() instead.\n",
            "  with gr.Blocks(theme=theme, title=\"Smart Plant System\", js=js_toggle) as demo:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Vision Model Loaded!\n",
            "\n",
            "üöÄ Launching System...\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://51ae4a979923898df7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://51ae4a979923898df7.gradio.live\" width=\"100%\" height=\"900\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ==========================================\n",
        "# PART 3: MAIN EXECUTION\n",
        "# ==========================================\n",
        "\n",
        "print(\"üîÑ Connecting to Google Drive... Please approve.\")\n",
        "try:\n",
        "    auth.authenticate_user()\n",
        "    drive_service = build('drive', 'v3')\n",
        "    print(\"‚úÖ Drive Connected!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Drive Error: {e}\")\n",
        "\n",
        "# 1. Load Files & Build Index\n",
        "files = get_files_from_folder(FOLDER_ID)\n",
        "if files:\n",
        "    print(f\"üìÇ Found {len(files)} documents.\")\n",
        "    for i, file in enumerate(files, 1):\n",
        "        doc_id = str(i)\n",
        "        DOC_TITLES[doc_id] = file['name']\n",
        "        content = fetch_gdoc_content(file['id']).strip()\n",
        "        if content: ARTICLES[doc_id] = content\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No documents found or wrong Folder ID.\")\n",
        "\n",
        "engine = LectureSearchEngine()\n",
        "if ARTICLES:\n",
        "    print(\"üìö Building Search Index...\")\n",
        "    engine.build_index(ARTICLES, DOC_TITLES)\n",
        "\n",
        "# 2. Setup AI Models\n",
        "ACTIVE_MODEL = get_working_model()\n",
        "print(f\"ü§ñ Active Text AI: {ACTIVE_MODEL}\")\n",
        "\n",
        "print(f\"üîÑ Loading Vision Model ({MODEL_ID})...\")\n",
        "try:\n",
        "    plant_classifier = pipeline(\"image-classification\", model=MODEL_ID)\n",
        "    print(\"‚úÖ Vision Model Loaded!\")\n",
        "except:\n",
        "    print(\"‚ùå Vision Model Failed to Load.\")\n",
        "    plant_classifier = None\n",
        "\n",
        "# 3. Launch Gradio UI\n",
        "print(\"\\nüöÄ Launching System...\")\n",
        "\n",
        "# JavaScript for Light/Dark Mode Toggle\n",
        "js_toggle = \"\"\"\n",
        "function toggleTheme() {\n",
        "    const body = document.querySelector('body');\n",
        "    if (body.classList.contains('dark')) {\n",
        "        body.classList.remove('dark');\n",
        "    } else {\n",
        "        body.classList.add('dark');\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Custom Green Theme\n",
        "theme = gr.themes.Soft(\n",
        "    primary_hue=\"green\",\n",
        "    secondary_hue=\"emerald\",\n",
        ").set(\n",
        "    body_background_fill=\"*neutral_50\",\n",
        "    block_background_fill=\"*neutral_100\"\n",
        ")\n",
        "\n",
        "with gr.Blocks(theme=theme, title=\"Smart Plant System\", js=js_toggle) as demo:\n",
        "\n",
        "    # Header Section\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=5):\n",
        "            gr.Markdown(\"# üå± Smart Plant System Ultimate\")\n",
        "        with gr.Column(scale=1):\n",
        "            # Toggle Button\n",
        "            mode_btn = gr.Button(\"üåó Light/Dark Mode\", variant=\"secondary\")\n",
        "            mode_btn.click(None, None, None, js=\"toggleTheme\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "\n",
        "        # Tab 1: Image AI\n",
        "        with gr.TabItem(\"1. Image (AI) üì∏\"):\n",
        "            gr.Markdown(\"### üçÉ Plant Disease Detection\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    img_input = gr.Image(height=300, label=\"Upload Leaf Photo üì∑\", type=\"numpy\")\n",
        "                    analyze_btn = gr.Button(\"üîç Analyze Leaf\", variant=\"primary\")\n",
        "                with gr.Column():\n",
        "                    img_out = gr.Textbox(label=\"AI Diagnosis ü§ñ\", lines=4, placeholder=\"Waiting for image...\")\n",
        "            analyze_btn.click(analyze_image, inputs=img_input, outputs=img_out)\n",
        "\n",
        "        # Tab 2: IoT Data\n",
        "        with gr.TabItem(\"2. IoT Data üìä\"):\n",
        "            gr.Markdown(\"### üì° Sensor History Analysis\")\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    gr.Markdown(\"**Select Sensors:**\")\n",
        "                    c1 = gr.Checkbox(label=\"Temperature üå°Ô∏è\", value=True)\n",
        "                    c2 = gr.Checkbox(label=\"Humidity üíß\")\n",
        "                    c3 = gr.Checkbox(label=\"Soil Moisture üåø\")\n",
        "                    c4 = gr.Checkbox(label=\"Export JSON üíæ\")\n",
        "                    lim = gr.Number(value=20, label=\"Data Limit üî¢\")\n",
        "                    btn = gr.Button(\"üì• Fetch Data\", variant=\"primary\")\n",
        "\n",
        "                with gr.Column(scale=3):\n",
        "                    p1 = gr.Plot(show_label=False)\n",
        "                    p2 = gr.Plot(show_label=False)\n",
        "                    p3 = gr.Plot(show_label=False)\n",
        "\n",
        "            with gr.Row():\n",
        "                f_out = gr.File(height=50, label=\"Download JSON\")\n",
        "                l_out = gr.Textbox(label=\"System Log üìù\", lines=1)\n",
        "\n",
        "            btn.click(update_iot_view, inputs=[c1,c2,c3,c4,lim], outputs=[p1,p2,p3,f_out,l_out])\n",
        "\n",
        "        # Tab 3: Search Docs\n",
        "        with gr.TabItem(\"3. Search Docs üîç\"):\n",
        "            gr.Markdown(\"### üìö Knowledge Base Search\")\n",
        "            with gr.Row():\n",
        "                txt_in = gr.Textbox(label=\"Ask a Question\", placeholder=\"How does photosynthesis work?...\", scale=4)\n",
        "                search_btn = gr.Button(\"üîé Search\", variant=\"primary\", scale=1)\n",
        "\n",
        "            res_out = gr.Textbox(label=\"AI & Doc Results üí°\", lines=12)\n",
        "            search_btn.click(search_engine_rag, inputs=txt_in, outputs=res_out)\n",
        "\n",
        "            with gr.Accordion(\"üõ†Ô∏è Index Debug View\", open=False):\n",
        "                gr.Dataframe(get_index_table)\n",
        "\n",
        "        # Tab 4: Dashboard\n",
        "        with gr.TabItem(\"4. Dashboard üéõÔ∏è\"):\n",
        "            gr.Markdown(\"### ‚ö° Live Monitor\")\n",
        "            dash_btn = gr.Button(\"üîÑ Sync Live Data\", variant=\"primary\")\n",
        "\n",
        "            # Live Metrics\n",
        "            with gr.Row():\n",
        "                b1 = gr.Textbox(label=\"Temp üå°Ô∏è\")\n",
        "                b2 = gr.Textbox(label=\"Humidity üíß\")\n",
        "                b3 = gr.Textbox(label=\"Soil üåø\")\n",
        "                b4 = gr.Textbox(label=\"Status üö¶\")\n",
        "\n",
        "            # Live Charts\n",
        "            with gr.Row():\n",
        "                dp1 = gr.Plot(label=\"Temp\")\n",
        "                dp2 = gr.Plot(label=\"Humidity\")\n",
        "            with gr.Row():\n",
        "                dp3 = gr.Plot(label=\"Soil\")\n",
        "\n",
        "            dash_btn.click(refresh_dashboard_real, outputs=[dp1,dp2,dp3,b1,b2,b3,b4])\n",
        "\n",
        "        # Tab 5: Report\n",
        "        with gr.TabItem(\"5. PDF Report üìë\"):\n",
        "            gr.Markdown(\"### üìÑ Generate Summary Report\")\n",
        "            report_btn = gr.Button(\"üñ®Ô∏è Generate PDF\", variant=\"primary\")\n",
        "            with gr.Row():\n",
        "                pdf_file = gr.File(label=\"Download PDF üì•\")\n",
        "                report_log = gr.Textbox(label=\"Log üìù\", lines=2)\n",
        "            report_btn.click(generate_pdf_report, outputs=[pdf_file, report_log])\n",
        "\n",
        "demo.launch(inline=True, height=900, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
